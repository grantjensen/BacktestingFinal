{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where we create a model. In this case we take in CleanedSpy.csv, which is data only from SPY. It is run through dataWrangling, and then run here. The basic goal of this file is to create a RandomForestRegressor model from mlflow.sklearn. We also take advantage of timeseriescv, which models Marcos Prado's method for a train/test split of the data. Essentially, we make sure to purge any data which is placed in the train set, but the model is asked to predict on data found in the test set. Since we are currently running with 1M candlestick data, this only deletes a very small number of points, but would prove very useful for larger time frames to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>pred_times</th>\n",
       "      <th>Volume</th>\n",
       "      <th>logChange</th>\n",
       "      <th>label</th>\n",
       "      <th>prev1</th>\n",
       "      <th>prev2</th>\n",
       "      <th>prev3</th>\n",
       "      <th>prev4</th>\n",
       "      <th>prevVol1</th>\n",
       "      <th>prevVol2</th>\n",
       "      <th>prevVol3</th>\n",
       "      <th>prevVol4</th>\n",
       "      <th>eval_times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1562170800</td>\n",
       "      <td>117422.0</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50947.0</td>\n",
       "      <td>9238.0</td>\n",
       "      <td>12661.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1562170860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1562171520</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>117422.0</td>\n",
       "      <td>50947.0</td>\n",
       "      <td>9238.0</td>\n",
       "      <td>12661.0</td>\n",
       "      <td>1562171580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1562172240</td>\n",
       "      <td>3308.0</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>117422.0</td>\n",
       "      <td>50947.0</td>\n",
       "      <td>9238.0</td>\n",
       "      <td>1562172300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1562172960</td>\n",
       "      <td>690.0</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>3308.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>117422.0</td>\n",
       "      <td>50947.0</td>\n",
       "      <td>1562173020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1562173620</td>\n",
       "      <td>8819.0</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>-0.000504</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>690.0</td>\n",
       "      <td>3308.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>117422.0</td>\n",
       "      <td>1562173680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118173</th>\n",
       "      <td>1</td>\n",
       "      <td>1592870040</td>\n",
       "      <td>284753.0</td>\n",
       "      <td>-0.000451</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>525818.0</td>\n",
       "      <td>283778.0</td>\n",
       "      <td>209723.0</td>\n",
       "      <td>657198.0</td>\n",
       "      <td>1592870100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118174</th>\n",
       "      <td>1</td>\n",
       "      <td>1592870100</td>\n",
       "      <td>399185.0</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>-0.000451</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>284753.0</td>\n",
       "      <td>525818.0</td>\n",
       "      <td>283778.0</td>\n",
       "      <td>209723.0</td>\n",
       "      <td>1592870160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118175</th>\n",
       "      <td>1</td>\n",
       "      <td>1592870160</td>\n",
       "      <td>466966.0</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>-0.000451</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>399185.0</td>\n",
       "      <td>284753.0</td>\n",
       "      <td>525818.0</td>\n",
       "      <td>283778.0</td>\n",
       "      <td>1592870220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118176</th>\n",
       "      <td>1</td>\n",
       "      <td>1592870220</td>\n",
       "      <td>471539.0</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>-0.000451</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>466966.0</td>\n",
       "      <td>399185.0</td>\n",
       "      <td>284753.0</td>\n",
       "      <td>525818.0</td>\n",
       "      <td>1592870280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118177</th>\n",
       "      <td>1</td>\n",
       "      <td>1592870280</td>\n",
       "      <td>448895.0</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>-0.000451</td>\n",
       "      <td>471539.0</td>\n",
       "      <td>466966.0</td>\n",
       "      <td>399185.0</td>\n",
       "      <td>284753.0</td>\n",
       "      <td>1592870340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ticker  pred_times    Volume  logChange     label     prev1     prev2  \\\n",
       "0            1  1562170800  117422.0  -0.000101 -0.000168 -0.000134  0.000202   \n",
       "1            1  1562171520    1000.0  -0.000168  0.000269 -0.000101 -0.000134   \n",
       "2            1  1562172240    3308.0   0.000269  0.000067 -0.000168 -0.000101   \n",
       "3            1  1562172960     690.0   0.000067 -0.000168  0.000269 -0.000168   \n",
       "4            1  1562173620    8819.0  -0.000168 -0.000504  0.000067  0.000269   \n",
       "...        ...         ...       ...        ...       ...       ...       ...   \n",
       "118173       1  1592870040  284753.0  -0.000451  0.000773  0.000515  0.000661   \n",
       "118174       1  1592870100  399185.0   0.000773  0.000169 -0.000451  0.000515   \n",
       "118175       1  1592870160  466966.0   0.000169 -0.000072  0.000773 -0.000451   \n",
       "118176       1  1592870220  471539.0  -0.000072 -0.000064  0.000169  0.000773   \n",
       "118177       1  1592870280  448895.0  -0.000064  0.000451 -0.000072  0.000169   \n",
       "\n",
       "           prev3     prev4  prevVol1  prevVol2  prevVol3  prevVol4  eval_times  \n",
       "0      -0.000403  0.000000   50947.0    9238.0   12661.0     100.0  1562170860  \n",
       "1       0.000202 -0.000403  117422.0   50947.0    9238.0   12661.0  1562171580  \n",
       "2      -0.000134  0.000202    1000.0  117422.0   50947.0    9238.0  1562172300  \n",
       "3      -0.000101 -0.000134    3308.0    1000.0  117422.0   50947.0  1562173020  \n",
       "4      -0.000168 -0.000101     690.0    3308.0    1000.0  117422.0  1562173680  \n",
       "...          ...       ...       ...       ...       ...       ...         ...  \n",
       "118173 -0.000193  0.000403  525818.0  283778.0  209723.0  657198.0  1592870100  \n",
       "118174  0.000661 -0.000193  284753.0  525818.0  283778.0  209723.0  1592870160  \n",
       "118175  0.000515  0.000661  399185.0  284753.0  525818.0  283778.0  1592870220  \n",
       "118176 -0.000451  0.000515  466966.0  399185.0  284753.0  525818.0  1592870280  \n",
       "118177  0.000773 -0.000451  471539.0  466966.0  399185.0  284753.0  1592870340  \n",
       "\n",
       "[118178 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Prep pandas df for timeseriescv\n",
    "import pandas as pd\n",
    "pdDf=pd.read_csv(\"CleanedSpy.csv\",index_col=0)\n",
    "pdDf=pdDf.rename(columns={\"Time\": \"pred_times\"})\n",
    "pdDf['eval_times']=pdDf['pred_times']+60;#Change to 300 for 5 min for example\n",
    "\n",
    "display(pdDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USING MLFLOW library instead\n",
    "from timeseriescv import cross_validation as cv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import tee\n",
    "\n",
    "train, test=train_test_split(pdDf, test_size=0.2, shuffle=False)\n",
    "splits=8\n",
    "crossval=cv.PurgedWalkForwardCV(n_splits=splits+2) #Default settings: n_splits=10, n_test_splits=1, min_train_splits=2, max_train_splits=None\n",
    "crossval=crossval.split(train, train['label'],train['pred_times'],train['eval_times'],False)\n",
    "#True above means identical time intervals as opposed to identical sample splits\n",
    "crossval,crossval_backup=tee(crossval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [3,4,5,6],\n",
    "    'max_features': [8,10,11],\n",
    "    'min_samples_leaf': [3,4,5],\n",
    "    'min_samples_split': [8,10,12],\n",
    "    'n_estimators': [100,200,300,1000]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor(random_state=1)\n",
    "# Instantiate the grid search model\n",
    "rndm_search = RandomizedSearchCV(\n",
    "    estimator = rf, param_distributions = param_grid, n_iter=20,cv = crossval, scoring='r2', n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a evaluation function\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "def evaluate(model, test_features, test_labels):\n",
    "        predictions = model.predict(test_features)\n",
    "        r2=r2_score(test_labels, predictions)\n",
    "        print('Model Performance')\n",
    "        print('r2: {:0.4f}.'.format(r2))\n",
    "        return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "from dask.distributed import Client, progress\n",
    "client = Client()\n",
    "#Use dask to parallelize the fit process, and \n",
    "with joblib.parallel_backend('dask'):\n",
    "    rndm_search.fit(train[['Ticker','Volume','prevVol1','prevVol2','prevVol3','prevVol4',\n",
    "                          'logChange','prev1','prev2','prev3','prev4']],train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>275.673776</td>\n",
       "      <td>14.325535</td>\n",
       "      <td>0.125915</td>\n",
       "      <td>0.052909</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106508</td>\n",
       "      <td>-0.024332</td>\n",
       "      <td>-0.006632</td>\n",
       "      <td>-0.093335</td>\n",
       "      <td>-0.045470</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>-0.017478</td>\n",
       "      <td>-0.047641</td>\n",
       "      <td>0.040977</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89.464901</td>\n",
       "      <td>14.077462</td>\n",
       "      <td>0.048406</td>\n",
       "      <td>0.005016</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089053</td>\n",
       "      <td>-0.026138</td>\n",
       "      <td>-0.008275</td>\n",
       "      <td>-0.089342</td>\n",
       "      <td>-0.058211</td>\n",
       "      <td>-0.006675</td>\n",
       "      <td>-0.017446</td>\n",
       "      <td>-0.048579</td>\n",
       "      <td>0.035817</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181.710030</td>\n",
       "      <td>33.694278</td>\n",
       "      <td>0.124204</td>\n",
       "      <td>0.131861</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029406</td>\n",
       "      <td>-0.022136</td>\n",
       "      <td>-0.005441</td>\n",
       "      <td>-0.076147</td>\n",
       "      <td>-0.012086</td>\n",
       "      <td>0.009580</td>\n",
       "      <td>-0.009377</td>\n",
       "      <td>-0.025483</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>566.466896</td>\n",
       "      <td>152.833603</td>\n",
       "      <td>0.352818</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029351</td>\n",
       "      <td>-0.017725</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>-0.078030</td>\n",
       "      <td>-0.010320</td>\n",
       "      <td>0.009470</td>\n",
       "      <td>-0.010652</td>\n",
       "      <td>-0.023671</td>\n",
       "      <td>0.026932</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>568.150436</td>\n",
       "      <td>144.463303</td>\n",
       "      <td>0.415001</td>\n",
       "      <td>0.240473</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067500</td>\n",
       "      <td>-0.013472</td>\n",
       "      <td>-0.001169</td>\n",
       "      <td>-0.091332</td>\n",
       "      <td>-0.006212</td>\n",
       "      <td>0.014867</td>\n",
       "      <td>-0.020766</td>\n",
       "      <td>-0.036182</td>\n",
       "      <td>0.041964</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     275.673776     14.325535         0.125915        0.052909   \n",
       "1      89.464901     14.077462         0.048406        0.005016   \n",
       "2     181.710030     33.694278         0.124204        0.131861   \n",
       "3     566.466896    152.833603         0.352818        0.025800   \n",
       "4     568.150436    144.463303         0.415001        0.240473   \n",
       "\n",
       "  param_n_estimators param_min_samples_split param_min_samples_leaf  \\\n",
       "0                300                       8                      5   \n",
       "1                100                      10                      5   \n",
       "2                200                      10                      3   \n",
       "3               1000                      10                      3   \n",
       "4               1000                      10                      4   \n",
       "\n",
       "  param_max_features param_max_depth param_bootstrap  ... split1_test_score  \\\n",
       "0                  8               6           False  ...         -0.106508   \n",
       "1                 10               5           False  ...         -0.089053   \n",
       "2                 10               6            True  ...         -0.029406   \n",
       "3                 11               5            True  ...         -0.029351   \n",
       "4                  8               3           False  ...         -0.067500   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0          -0.024332          -0.006632          -0.093335          -0.045470   \n",
       "1          -0.026138          -0.008275          -0.089342          -0.058211   \n",
       "2          -0.022136          -0.005441          -0.076147          -0.012086   \n",
       "3          -0.017725          -0.000694          -0.078030          -0.010320   \n",
       "4          -0.013472          -0.001169          -0.091332          -0.006212   \n",
       "\n",
       "   split6_test_score  split7_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.004838          -0.017478        -0.047641        0.040977   \n",
       "1          -0.006675          -0.017446        -0.048579        0.035817   \n",
       "2           0.009580          -0.009377        -0.025483        0.026872   \n",
       "3           0.009470          -0.010652        -0.023671        0.026932   \n",
       "4           0.014867          -0.020766        -0.036182        0.041964   \n",
       "\n",
       "   rank_test_score  \n",
       "0               16  \n",
       "1               17  \n",
       "2                9  \n",
       "3                8  \n",
       "4               12  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(rndm_search.cv_results_).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: \n",
      "{'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 5, 'max_features': 11, 'max_depth': 3, 'bootstrap': True}\n",
      "\n",
      "Test\n",
      "Model Performance\n",
      "r2: -0.0025.\n",
      "\n",
      "Train\n",
      "Model Performance\n",
      "r2: 0.0284.\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters: \")\n",
    "print(rndm_search.best_params_)\n",
    "best_grid = rndm_search.best_estimator_\n",
    "print(\"\\nTest\")\n",
    "grid_accuracy = evaluate(best_grid, test[['Ticker','Volume','prevVol1','prevVol2','prevVol3','prevVol4',\n",
    "                          'logChange','prev1','prev2','prev3','prev4']], test['label'])\n",
    "print(\"\\nTrain\")\n",
    "grid_accuracy = evaluate(best_grid, train[['Ticker','Volume','prevVol1','prevVol2','prevVol3','prevVol4',\n",
    "                          'logChange','prev1','prev2','prev3','prev4']], train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Obtain matrix with rows = fold #, cols=train/test, \n",
    "data=[]\n",
    "for i in range(splits):\n",
    "    train_temp,test_temp=next(crossval_backup)\n",
    "    data.append([train_temp[-1]/len(pdDf),(test_temp[1]-train_temp[-1])/len(pdDf),test_temp[-1]/len(pdDf)])\n",
    "#Need to take transpose of data\n",
    "data=list(map(list,zip(*data)))\n",
    "#Need to subtract training from test\n",
    "import operator\n",
    "data[2]=list(map(operator.sub, data[2], data[0]))\n",
    "data[2]=list(map(operator.add, data[2], data[1]))\n",
    "\n",
    "rows=('Train','Purge','Test')\n",
    "columns=['Fold %d'%x for x in range(1,splits+1)]\n",
    "#columns.append(\"Holdout\")\n",
    "values=np.arange(0,1,0.1)\n",
    "\n",
    "colors = plt.cm.BuPu([0.25,0,0.5])\n",
    "n_rows = len(data)\n",
    "\n",
    "index = np.arange(len(columns)) + 0.3\n",
    "bar_width = 0.4\n",
    "\n",
    "# Initialize the vertical-offset for the stacked bar chart.\n",
    "y_offset = np.zeros(len(columns))\n",
    "\n",
    "# Plot bars and create text labels for the table\n",
    "cell_text = []\n",
    "for row in range(n_rows):\n",
    "    plt.bar(index, data[row], bar_width, bottom=y_offset, color=colors[row])\n",
    "    y_offset = y_offset + data[row]\n",
    "    cell_text.append(['%1f' % x for x in y_offset])\n",
    "# Reverse colors and text labels to display the last value at the top.\n",
    "colors = colors[::-1]\n",
    "cell_text.reverse()\n",
    "\n",
    "# Add a table at the bottom of the axes\n",
    "the_table = plt.table(cellText=cell_text,\n",
    "                      rowLabels=rows,\n",
    "                      rowColours=colors,\n",
    "                      colLabels=columns,\n",
    "                      loc='bottom')\n",
    "\n",
    "# Adjust layout to make room for the table:\n",
    "plt.subplots_adjust(left=0.2, bottom=0.2)\n",
    "\n",
    "plt.ylabel(\"Cross Validation %\")\n",
    "plt.yticks(values, ['%1.1f' % val for val in values])\n",
    "plt.xticks([])\n",
    "plt.title('Cross Validation Train/Test split')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the model\n",
    "import pickle\n",
    "pkl_filename = \"myModel.cpickle\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(rndm_search.best_estimator_, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of how to import the model\n",
    "import cloudpickle as cp\n",
    "from urllib.request import urlopen\n",
    "model = cp.load(urlopen(\"https://raw.githubusercontent.com/grantjensen/Backtesting2/master/myModel.cpickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.80409709e-05])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example prediction\n",
    "model.predict([[1, 73240, 76141, 132351, 111472, 91095, -0.0001976145111942757, -0.000761861801266224, 0.00047962308188520823, 0.0004798532305751543, 0.0004518370074894487]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
